{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Trainning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## hyper-parameter"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# hyper-parameters\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import sagemaker\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "role = get_execution_role()\n",
    "\n",
    "pretrain_date_str = \"\"\n",
    "pretrain_job_name = \"\"\n",
    "train_date_str = \"training_dataset/\"\n",
    "test_date_str = \"test_dataset/\"\n",
    "\n",
    "class config(object):\n",
    "    # Common parameters\n",
    "    TAGS = [{'Key': 'Service', 'Value': 'SageMaker'}]\n",
    "    BUCKET_NAME = 'bucket_name'\n",
    "    PREFIX_PATH = 'prefix_path'\n",
    "    \n",
    "    # Training parameters\n",
    "    TRAIN_JOB_NAME = 'YOYI-training-lixu'\n",
    "    AI_EPOCHS = 10\n",
    "    AI_BATCH_SIZE = 8192\n",
    "    AI_LR = 0.001\n",
    "    AI_L2_REG = 0\n",
    "    SM_TRAIN_EC2_TYPE = 'ml.m5.2xlarge'\n",
    "    SM_TRAIN_EC2_NUM = 20\n",
    "    PROCESSES_PER_HOST = 8\n",
    "    TRAIN_CODE_PATH = 'code'\n",
    "    SM_IAM_ROLE = role\n",
    "    TRAIN_VOL_SIZE = 8\n",
    "    TRAIN_DATA_SIZE = 363447989\n",
    "    VALIDATION_DATA_SIZE = 2 * AI_BATCH_SIZE\n",
    "    ALGO_B_START = 0\n",
    "    ALGO_B_LIMIT = 120\n",
    "    ALGO_B_DELTA = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## trainning"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "### Training ###\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import sagemaker\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "\n",
    "hyperparameters = {\n",
    "    'epochs': config.AI_EPOCHS,\n",
    "    'batch_size': config.AI_BATCH_SIZE,\n",
    "    'learning_rate': config.AI_LR,\n",
    "    'l2_reg': config.AI_L2_REG,\n",
    "    'process_per_host': config.PROCESSES_PER_HOST,\n",
    "    'training_data_size': config.TRAIN_DATA_SIZE,\n",
    "    'validation_data_size': config.VALIDATION_DATA_SIZE,\n",
    "    'b_start': config.ALGO_B_START,\n",
    "    'b_limit': config.ALGO_B_LIMIT,\n",
    "    'b_delta': config.ALGO_B_DELTA,\n",
    "    'base_job_name': config.TRAIN_JOB_NAME\n",
    "}\n",
    "\n",
    "metric_definitions = [\n",
    "    {'Name': 'loss', 'Regex': 'loss: (\\d+\\.\\d+)'},\n",
    "    {'Name': 'val_loss', 'Regex': 'val_loss: (\\d+\\.\\d+)'}\n",
    "]\n",
    "\n",
    "train_path = os.path.join(\n",
    "    \"s3://\",\n",
    "    config.BUCKET_NAME,\n",
    "    config.PREFIX_PATH,\n",
    "    train_date_str\n",
    ")\n",
    "\n",
    "code_location = os.path.join(\n",
    "    \"s3://\",\n",
    "    config.BUCKET_NAME,\n",
    "    config.PREFIX_PATH,\n",
    "    \"custom_code_upload\"\n",
    ")\n",
    "\n",
    "model_uri = os.path.join(\n",
    "    \"s3://\",\n",
    "    config.BUCKET_NAME,\n",
    "    config.PREFIX_PATH,\n",
    "    \"model\",\n",
    "    \"date={}\".format(pretrain_date_str),\n",
    "    \"{}\".format(pretrain_job_name),\n",
    "    \"output\",\n",
    "    \"model.tar.gz\"\n",
    ")\n",
    "\n",
    "output_path = os.path.join(\n",
    "    \"s3://\",\n",
    "    config.BUCKET_NAME,\n",
    "    config.PREFIX_PATH,\n",
    "    \"model\",\n",
    "    \"output_\" + train_date_str\n",
    ")\n",
    "\n",
    "train_input = sagemaker.session.s3_input(\n",
    "    s3_data=train_path,\n",
    "    distribution=\"ShardedByS3Key\" if (config.SM_TRAIN_EC2_TYPE != \"local\") else \"FullyReplicated\"\n",
    ")\n",
    "\n",
    "inputs = {\n",
    "    'train': train_input\n",
    "}\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"training-textline_rag_hash_emb.py\",\n",
    "    source_dir=config.TRAIN_CODE_PATH,\n",
    "    code_location=code_location,\n",
    "    role=config.SM_IAM_ROLE,\n",
    "    train_instance_count=config.SM_TRAIN_EC2_NUM,\n",
    "    train_instance_type =config.SM_TRAIN_EC2_TYPE,\n",
    "    hyperparameters=hyperparameters,\n",
    "    metric_definitions=metric_definitions,\n",
    "    train_volume_size=config.TRAIN_VOL_SIZE,\n",
    "    distributions={'mpi': {'enabled': True}},\n",
    "    script_mode=True,\n",
    "    framework_version='2.4.1',\n",
    "    py_version='py37',\n",
    "    train_use_spot_instances=(config.SM_TRAIN_EC2_TYPE != \"local\"),\n",
    "    train_max_run=6 * 3600,\n",
    "    train_max_wait=6 * 3600,\n",
    "    tags=config.TAGS,\n",
    "    output_path=output_path,\n",
    "    container_log_level=logging.ERROR,\n",
    "    base_job_name=config.TRAIN_JOB_NAME\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "Parameter distribution will be renamed to {'mpi': {'enabled': True}} in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2021-08-11 13:46:29 Starting - Starting the training job...\n",
      "2021-08-11 13:46:31 Starting - Launching requested ML instances......\n",
      "2021-08-11 13:47:46 Starting - Preparing the instances for training............\n",
      "2021-08-11 13:49:40 Downloading - Downloading input data.........\n",
      "2021-08-11 13:51:20 Training - Downloading the training image..\u001b[32m2021-08-11 13:51:37.534560: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:37.541995: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:37.721030: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.324866: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.331196: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.493747: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:37.768925: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:37.775872: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:37.953772: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:37.364328: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:37.372038: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:37.539189: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.320190: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.328661: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.514505: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.060060: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.070531: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:37.258661: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:37.751271: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:37.759121: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:37.934743: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.722182: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.729706: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:36.889648: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:38.423244: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:38.433478: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:38.618730: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[32mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:41.946676: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:41.952456: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:42.079184: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:38.459909: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:38.468741: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:38.640608: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.371204: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.379201: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.544413: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[32mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:42.330616: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:42.340261: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:42.536938: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[35mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[36mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:43.454673: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:43.462970: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[32mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[32mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:43.720503: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:43.727067: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[35mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[36mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:43.704722: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:43.714829: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:43.903640: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:43.643096: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:42.454931: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:42.461880: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:42.622049: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:42.135044: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:42.141642: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:42.293751: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:43.875275: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.511152: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.518969: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:42.730310: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[36mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[32mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[32mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[32mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[32mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[35mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[36mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[36mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[36mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[32mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[32mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[35mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[36mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[36mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[36mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[33mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[33mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[33m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[33mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[33mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:51,614 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:52,162 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:52,257 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[33mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[33mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:52,811 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:52,907 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\n",
      "2021-08-11 13:51:44 Training - Training image download completed. Training in progress.\u001b[34m2021-08-11 13:51:43.413242: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:43.423721: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:43.629838: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[32mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[32mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[32mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[32m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[36mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:51,552 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:51,652 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[36mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[32mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,474 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,574 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,454 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,560 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:52,182 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:52,274 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:51,939 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:52,034 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:51,713 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:52,394 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:52,503 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:52,255 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:52,354 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,874 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:51,969 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[32mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[32mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[32mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:52,167 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[32m2021-08-11 13:51:52,262 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:52,390 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:52,486 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[35mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[36mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[36mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[36mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:54,671 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:54,040 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:54,135 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:55,515 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:55,578 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[36m2021-08-11 13:51:54,765 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[33mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[33mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[33mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[36mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[36mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[36mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\u001b[0m\n",
      "\u001b[33mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[36m    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[35mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:58,067 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-08-11 13:51:58,161 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:58,588 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:58,649 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:58,656 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[33mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:58,234 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:51:58,327 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:51:58,767 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[33mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[33mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[33mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[33m2021-08-11 13:52:00,056 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[33m2021-08-11 13:52:00,155 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[36mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[36mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[36mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[36mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[36m2021-08-11 13:52:00,201 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[36m2021-08-11 13:52:00,295 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35mCollecting pandas==1.1.5\n",
      "  Downloading pandas-1.1.5-cp37-cp37m-manylinux1_x86_64.whl (9.5 MB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2.8.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (2021.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/site-packages (from pandas==1.1.5->-r requirements.txt (line 1)) (1.19.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.1.5->-r requirements.txt (line 1)) (1.15.0)\u001b[0m\n",
      "\u001b[35mInstalling collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.1.0\n",
      "    Uninstalling pandas-1.1.0:\n",
      "      Successfully uninstalled pandas-1.1.0\u001b[0m\n",
      "\u001b[35mSuccessfully installed pandas-1.1.5\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as root will break packages and permissions. You should install packages reliably by using venv: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35mWARNING: You are using pip version 21.1.1; however, version 21.2.3 is available.\u001b[0m\n",
      "\u001b[35mYou should consider upgrading via the '/usr/local/bin/python3.7 -m pip install --upgrade pip' command.\n",
      "\u001b[0m\n",
      "\u001b[35m2021-08-11 13:52:55,428 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[35m2021-08-11 13:52:55,521 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:55,856 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:55,922 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:55,928 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:55,995 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,001 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,065 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,072 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,134 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,140 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,201 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,208 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,271 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,277 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,344 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,351 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,415 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,422 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,487 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,493 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,556 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,563 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,625 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,631 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,693 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,700 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,764 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,770 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,836 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,842 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_7.6p1)\u001b[0m\n",
      "\u001b[34m2021-08-11 13:52:56,906 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m Data for JOB [62905,1] offset 0 Total slots allocated 20\n",
      "\n",
      " ========================   JOB MAP   ========================\n",
      "\n",
      " Data for node: ip-10-2-64-49#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 0 Bound: N/A\n",
      "\n",
      " Data for node: algo-2#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 1 Bound: N/A\n",
      "\n",
      " Data for node: algo-3#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 2 Bound: N/A\n",
      "\n",
      " Data for node: algo-4#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 3 Bound: N/A\n",
      "\n",
      " Data for node: algo-5#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 4 Bound: N/A\n",
      "\n",
      " Data for node: algo-6#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 5 Bound: N/A\n",
      "\n",
      " Data for node: algo-7#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 6 Bound: N/A\n",
      "\n",
      " Data for node: algo-8#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 7 Bound: N/A\n",
      "\n",
      " Data for node: algo-9#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 8 Bound: N/A\n",
      "\n",
      " Data for node: algo-10#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 9 Bound: N/A\n",
      "\n",
      " Data for node: algo-11#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 10 Bound: N/A\n",
      "\n",
      " Data for node: algo-12#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 11 Bound: N/A\n",
      "\n",
      " Data for node: algo-13#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 12 Bound: N/A\n",
      "\n",
      " Data for node: algo-14#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 13 Bound: N/A\n",
      "\n",
      " Data for node: algo-15#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 14 Bound: N/A\n",
      "\n",
      " Data for node: algo-16#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 15 Bound: N/A\n",
      "\n",
      " Data for node: algo-17#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 16 Bound: N/A\n",
      "\n",
      " Data for node: algo-18#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 17 Bound: N/A\n",
      "\n",
      " Data for node: algo-19#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 18 Bound: N/A\n",
      "\n",
      " Data for node: algo-20#011Num slots: 1#011Max slots: 0#011Num procs: 1\n",
      " #011Process OMPI jobid: [62905,1] App: 0 Process rank: 19 Bound: N/A\n",
      "\n",
      " =============================================================\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Training steps = 2217\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Validation steps = 2\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Initializing model\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:01.791 algo-10:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:01.799 algo-8:69 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:01.803 algo-5:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:01.802 algo-6:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:01.806 algo-2:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:01.809 algo-9:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:01.811 algo-4:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:01.812 algo-7:69 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:01.816 algo-11:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:01.818 algo-15:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:01.817 algo-17:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:01.836 algo-16:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:01.837 algo-3:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:01.840 algo-13:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:01.847 algo-12:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:01.848 algo-1:311 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:01.870 algo-19:69 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:01.878 algo-20:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:01.883 algo-14:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:01.983 algo-10:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:01.991 algo-5:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:01.997 algo-4:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:01.998 algo-6:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.002 algo-8:69 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:02.005 algo-10:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:02.005 algo-10:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.006 algo-17:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:02.006 algo-10:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:02.006 algo-10:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:[2021-08-11 13:53:02.006 algo-10:68 INFO hook.py:413] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.007 algo-9:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.005 algo-2:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.009 algo-7:69 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:02.014 algo-5:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:02.014 algo-5:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.012 algo-11:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:02.015 algo-5:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:02.015 algo-5:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:[2021-08-11 13:53:02.015 algo-5:68 INFO hook.py:413] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:02.017 algo-4:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:02.017 algo-4:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:02.018 algo-4:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:02.018 algo-4:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:[2021-08-11 13:53:02.018 algo-4:68 INFO hook.py:413] Monitoring the collections: losses, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.023 algo-15:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.023 algo-8:69 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.024 algo-8:69 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.024 algo-8:69 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.025 algo-8:69 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:[2021-08-11 13:53:02.025 algo-8:69 INFO hook.py:413] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:02.024 algo-6:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:02.024 algo-6:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:02.024 algo-6:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:02.025 algo-6:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:[2021-08-11 13:53:02.025 algo-6:68 INFO hook.py:413] Monitoring the collections: losses, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.029 algo-12:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.029 algo-17:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.029 algo-17:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.030 algo-9:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.029 algo-17:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.030 algo-17:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.030 algo-9:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:[2021-08-11 13:53:02.030 algo-17:68 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.031 algo-9:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.031 algo-9:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:[2021-08-11 13:53:02.031 algo-9:68 INFO hook.py:413] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.030 algo-2:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.030 algo-2:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.033 algo-7:69 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.033 algo-7:69 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.030 algo-2:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.031 algo-2:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:[2021-08-11 13:53:02.031 algo-2:68 INFO hook.py:413] Monitoring the collections: metrics, sm_metrics, losses\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.034 algo-7:69 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.034 algo-7:69 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:[2021-08-11 13:53:02.034 algo-7:69 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.039 algo-16:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.038 algo-11:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.038 algo-11:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.039 algo-11:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.039 algo-11:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:[2021-08-11 13:53:02.039 algo-11:68 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.040 algo-3:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.045 algo-15:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.045 algo-15:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.046 algo-15:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.046 algo-15:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:[2021-08-11 13:53:02.046 algo-15:68 INFO hook.py:413] Monitoring the collections: sm_metrics, losses, metrics\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.048 algo-12:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.049 algo-12:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.046 algo-13:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.049 algo-12:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.049 algo-12:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:[2021-08-11 13:53:02.049 algo-12:68 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.058 algo-1:311 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.059 algo-16:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.060 algo-16:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.060 algo-16:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.060 algo-16:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:[2021-08-11 13:53:02.061 algo-16:68 INFO hook.py:413] Monitoring the collections: losses, metrics, sm_metrics\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.063 algo-3:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.063 algo-3:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.064 algo-3:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.064 algo-3:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:[2021-08-11 13:53:02.064 algo-3:68 INFO hook.py:413] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.072 algo-13:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.072 algo-13:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.073 algo-13:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.073 algo-13:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:[2021-08-11 13:53:02.074 algo-13:68 INFO hook.py:413] Monitoring the collections: sm_metrics, metrics, losses\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.079 algo-1:311 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.079 algo-1:311 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.080 algo-1:311 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.080 algo-1:311 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:[2021-08-11 13:53:02.080 algo-1:311 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.085 algo-20:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.094 algo-19:69 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.107 algo-14:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.112 algo-20:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.112 algo-20:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.113 algo-20:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.113 algo-20:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:[2021-08-11 13:53:02.113 algo-20:68 INFO hook.py:413] Monitoring the collections: sm_metrics, losses, metrics\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.121 algo-19:69 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.121 algo-19:69 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.122 algo-19:69 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.122 algo-19:69 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:[2021-08-11 13:53:02.122 algo-19:69 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.133 algo-14:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.133 algo-14:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.134 algo-14:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.134 algo-14:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:[2021-08-11 13:53:02.134 algo-14:68 INFO hook.py:413] Monitoring the collections: losses, sm_metrics, metrics\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Model: \"model\"\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Layer (type)                    Output Shape         Param #     Connected to                     \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:==================================================================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:features (InputLayer)           [(None, None)]       0                                            \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:x_Embedding (Embedding)         (None, None, 10)     10240       features[0][0]                   \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:lambda (Lambda)                 (None, 10)           0           x_Embedding[0][0]                \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:o1_Dense_1 (Dense)              (None, 10)           110         lambda[0][0]                     \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:oh_Dense_1 (Dense)              (None, 10)           110         o1_Dense_1[0][0]                 \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:oh_Dense_2 (Dense)              (None, 10)           110         oh_Dense_1[0][0]                 \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:concatenate (Concatenate)       (None, 20)           0           o1_Dense_1[0][0]                 \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:                                                                 oh_Dense_2[0][0]                 \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:concat_Dense (Dense)            (None, 120)          2520        concatenate[0][0]                \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________[1,0]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:ground_truth (Softmax)          (None, 120)          0           concat_Dense[0][0]               \u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:==================================================================================================\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Total params: 13,090\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Trainable params: 13,090\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Non-trainable params: 0\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:__________________________________________________________________________________________________\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:None\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 1/10\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:03.804 algo-18:68 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.021 algo-18:68 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.047 algo-18:68 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.048 algo-18:68 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.048 algo-18:68 INFO hook.py:253] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.049 algo-18:68 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:[2021-08-11 13:53:04.049 algo-18:68 INFO hook.py:413] Monitoring the collections: sm_metrics, losses, metrics\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 175s - loss: 15243.7100 - val_loss: 13776.2578\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 2/10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 69s - loss: 14647.6465 - val_loss: 13681.4092\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 3/10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 63s - loss: 14478.2705 - val_loss: 13726.1953\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 4/10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 63s - loss: 14401.9219 - val_loss: 13621.2520\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 5/10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 63s - loss: 14416.7246 - val_loss: 13482.6064\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 6/10\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:2217/2217 - 62s - loss: 14352.7803 - val_loss: 13841.5830\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:Restoring model weights from the end of the best epoch.\u001b[0m\n",
      "\u001b[34m[1,8]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,11]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,12]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,9]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,19]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,18]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,17]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,4]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,1]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,5]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,3]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,16]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,6]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,13]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,7]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,15]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,10]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,2]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,14]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34m[1,0]<stdout>:Epoch 00006: early stopping\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-5,10.2.111.164' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.2.113.59' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-12,10.2.68.11' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-6,10.2.64.225' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-13,10.2.112.77' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-10,10.2.102.188' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-4,10.2.71.57' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-3,10.2.114.159' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-17,10.2.109.248' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-20,10.2.120.1' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-15,10.2.76.67' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-7,10.2.104.52' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-9,10.2.83.115' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-19,10.2.92.92' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-14,10.2.102.248' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-8,10.2.104.251' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-18,10.2.81.151' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-16,10.2.72.76' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-11,10.2.121.53' (ECDSA) to the list of known hosts.#015\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-08-11 13:52:59.879070: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-08-11 13:52:59.879206: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,6]<stderr>:2021-08-11 13:52:59.881729: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stderr>:2021-08-11 13:52:59.881871: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-08-11 13:52:59.881427: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-08-11 13:52:59.881563: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,18]<stderr>:2021-08-11 13:52:59.883453: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,18]<stderr>:2021-08-11 13:52:59.883627: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,11]<stderr>:2021-08-11 13:52:59.886826: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,11]<stderr>:2021-08-11 13:52:59.886994: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,16]<stderr>:2021-08-11 13:52:59.886023: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,16]<stderr>:2021-08-11 13:52:59.886169: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,8]<stderr>:2021-08-11 13:52:59.887308: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,8]<stderr>:2021-08-11 13:52:59.887451: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,14]<stderr>:2021-08-11 13:52:59.891183: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,14]<stderr>:2021-08-11 13:52:59.891321: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-08-11 13:52:59.892732: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-08-11 13:52:59.892871: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,15]<stderr>:2021-08-11 13:52:59.891757: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,15]<stderr>:2021-08-11 13:52:59.891905: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,4]<stderr>:2021-08-11 13:52:59.895068: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stderr>:2021-08-11 13:52:59.895214: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,19]<stderr>:2021-08-11 13:52:59.893623: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,19]<stderr>:2021-08-11 13:52:59.893776: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,7]<stderr>:2021-08-11 13:52:59.895416: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stderr>:2021-08-11 13:52:59.895563: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,10]<stderr>:2021-08-11 13:52:59.894234: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,10]<stderr>:2021-08-11 13:52:59.894403: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-08-11 13:52:59.895104: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-08-11 13:52:59.895257: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,5]<stderr>:2021-08-11 13:52:59.899311: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stderr>:2021-08-11 13:52:59.899463: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,9]<stderr>:2021-08-11 13:52:59.901997: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,9]<stderr>:2021-08-11 13:52:59.902162: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,12]<stderr>:2021-08-11 13:52:59.904021: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,12]<stderr>:2021-08-11 13:52:59.904176: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,17]<stderr>:2021-08-11 13:52:59.910238: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,17]<stderr>:2021-08-11 13:52:59.910417: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:2021-08-11 13:52:59.908850: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-08-11 13:52:59.911409: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,18]<stderr>:2021-08-11 13:52:59.913494: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,6]<stderr>:2021-08-11 13:52:59.913653: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,11]<stderr>:2021-08-11 13:52:59.916850: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,16]<stderr>:2021-08-11 13:52:59.915981: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,8]<stderr>:2021-08-11 13:52:59.917357: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,13]<stderr>:2021-08-11 13:52:59.918976: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,13]<stderr>:2021-08-11 13:52:59.919131: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m[1,14]<stderr>:2021-08-11 13:52:59.921104: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,15]<stderr>:2021-08-11 13:52:59.921777: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:2021-08-11 13:52:59.923126: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,4]<stderr>:2021-08-11 13:52:59.925132: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,19]<stderr>:2021-08-11 13:52:59.923562: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,7]<stderr>:2021-08-11 13:52:59.925499: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,10]<stderr>:2021-08-11 13:52:59.924229: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-08-11 13:52:59.926680: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,5]<stderr>:2021-08-11 13:52:59.929437: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,9]<stderr>:2021-08-11 13:52:59.931506: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,12]<stderr>:2021-08-11 13:52:59.934470: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,17]<stderr>:2021-08-11 13:52:59.941001: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,13]<stderr>:2021-08-11 13:52:59.949420: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m[1,14]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0294s vs `on_train_batch_end` time: 0.4514s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,14]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0294s vs `on_train_batch_end` time: 0.4514s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,11]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0298s vs `on_train_batch_end` time: 0.4443s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,11]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0298s vs `on_train_batch_end` time: 0.4443s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,6]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0301s vs `on_train_batch_end` time: 0.4307s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,6]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0301s vs `on_train_batch_end` time: 0.4307s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,12]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.4197s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,12]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.4197s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,19]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.3959s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,19]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.3959s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,15]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.4360s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,15]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0304s vs `on_train_batch_end` time: 0.4360s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,9]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0306s vs `on_train_batch_end` time: 0.4522s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,9]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0306s vs `on_train_batch_end` time: 0.4522s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.4286s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,2]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.4286s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,8]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0319s vs `on_train_batch_end` time: 0.4194s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,8]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0319s vs `on_train_batch_end` time: 0.4194s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.4412s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0318s vs `on_train_batch_end` time: 0.4412s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0320s vs `on_train_batch_end` time: 0.4302s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,3]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0320s vs `on_train_batch_end` time: 0.4302s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,18]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0321s vs `on_train_batch_end` time: 0.4090s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,18]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0321s vs `on_train_batch_end` time: 0.4090s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,4]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0322s vs `on_train_batch_end` time: 0.4232s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,4]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0322s vs `on_train_batch_end` time: 0.4232s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,10]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0324s vs `on_train_batch_end` time: 0.4289s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,10]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0324s vs `on_train_batch_end` time: 0.4289s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,5]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0335s vs `on_train_batch_end` time: 0.4303s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,5]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0335s vs `on_train_batch_end` time: 0.4303s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.4130s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0339s vs `on_train_batch_end` time: 0.4130s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,7]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.4273s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,7]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0349s vs `on_train_batch_end` time: 0.4273s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,13]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0361s vs `on_train_batch_end` time: 0.3910s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,13]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0361s vs `on_train_batch_end` time: 0.3910s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,16]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0373s vs `on_train_batch_end` time: 0.4118s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,16]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0373s vs `on_train_batch_end` time: 0.4118s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,17]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0475s vs `on_train_batch_end` time: 0.0639s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,17]<stderr>:WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0475s vs `on_train_batch_end` time: 0.0639s). Check your callbacks.\u001b[0m\n",
      "\u001b[34m[1,1]<stderr>:2021-08-11 13:55:44.685154: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-08-11 13:55:56.794486: W tensorflow/core/kernels/data/cache_dataset_ops.cc:757] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:2021-08-11 13:55:57.778847: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-1/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-1/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-2/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-2/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-3/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-3/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-4/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-4/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-5/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-5/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-6/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: ./checkpoint-6/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: /opt/ml/model/model1/1/assets\u001b[0m\n",
      "\u001b[34m[1,0]<stderr>:INFO:tensorflow:Assets written to: /opt/ml/model/model1/1/assets\n",
      "\u001b[0m\n",
      "\n",
      "2021-08-11 14:02:04 Uploading - Uploading generated training model\n",
      "2021-08-11 14:02:38 Completed - Training job completed\n",
      "Training seconds: 15560\n",
      "Billable seconds: 7540\n",
      "Managed Spot Training savings: 51.5%\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "os.system('rm -r model/')\n",
    "os.system('aws s3 cp ' + estimator.model_data + ' ./model/model.tar.gz')\n",
    "os.system('tar -zxvf ./model/model.tar.gz -C ./model')"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Testing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## load model - RaggedTensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# [Optional] - LOAD MODEL - RaggedTensor\n",
    "\n",
    "\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import logging\n",
    "import numpy as np\n",
    "import codecs\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from operator import add\n",
    "import boto3\n",
    "from subprocess import check_output\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.python.framework import ops\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import DenseFeatures\n",
    "from tensorflow.keras.layers import Reshape, Flatten, Concatenate, RepeatVector, Add, Subtract, Multiply, Dot, PReLU, Softmax, Activation\n",
    "from tensorflow.keras.layers import Dense, Lambda, Embedding, LocallyConnected1D, Permute, Dropout\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, MaxPool1D, LSTM, GRU\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError\n",
    "from tensorflow.keras.losses import MeanSquaredLogarithmicError, MeanAbsolutePercentageError, BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import MAE, MSE, MSLE, MAPE\n",
    "import horovod.tensorflow.keras as hvd\n",
    "\n",
    "\n",
    "B_START = config.ALGO_B_START\n",
    "B_LIMIT = config.ALGO_B_LIMIT\n",
    "B_DELTA = config.ALGO_B_DELTA\n",
    "\n",
    "def neighbourhood_likelihood_loss(y_true, y_pred):\n",
    "    return 0.\n",
    "\n",
    "def get_model(learning_rate, l2_reg, b_start, b_limit, b_delta):\n",
    "    price_bucket_num = int(math.floor((b_limit - b_start + K.epsilon()) / b_delta))\n",
    "    \n",
    "    ### Input Layers ###\n",
    "    input_tensor = Input(shape=(None,), ragged=True, dtype='int64', name='features')\n",
    "\n",
    "    ### Embedding Layers ###\n",
    "    input_embed_tensor = Embedding(1024, 10, name='x_Embedding')(input_tensor)\n",
    "    input_embed_tensor = Lambda(lambda x: tf.math.reduce_mean(x, axis=1))(input_embed_tensor)\n",
    "    \n",
    "    ### 1-Order Feature Extractor ###\n",
    "    x_o1_tensor = Dense(10, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), name='o1_Dense_1')(input_embed_tensor)\n",
    "    ### High-Order Feature Extractor ###\n",
    "    x_oh_tensor = Dense(10, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), name='oh_Dense_1')(x_o1_tensor)\n",
    "    x_oh_tensor = Dense(10, activation='relu', kernel_regularizer=regularizers.l2(l2_reg), name='oh_Dense_2')(x_oh_tensor)\n",
    "    \n",
    "    ### Output Layer ###\n",
    "    output_tensor = Concatenate()([x_o1_tensor, x_oh_tensor])\n",
    "    output_tensor = Dense(price_bucket_num, kernel_regularizer=regularizers.l2(l2_reg), name='concat_Dense')(output_tensor)\n",
    "    output_tensor = Softmax(name='ground_truth')(output_tensor)\n",
    "    \n",
    "    model = Model(inputs=input_tensor, \n",
    "                  outputs=output_tensor)\n",
    "    optimizer = optimizers.Adam(lr=learning_rate)\n",
    "    model.compile(\n",
    "        loss=neighbourhood_likelihood_loss,\n",
    "        optimizer=optimizer,\n",
    "        experimental_run_tf_function=False\n",
    "    )\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n",
    "model_dependencies = {'neighbourhood_likelihood_loss': neighbourhood_likelihood_loss}\n",
    "\n",
    "model = get_model(config.AI_LR, config.AI_L2_REG, config.ALGO_B_START, config.ALGO_B_LIMIT, config.ALGO_B_DELTA)\n",
    "model.load_weights('./model/model.h5')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "features (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "x_Embedding (Embedding)         (None, None, 10)     10240       features[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, 10)           0           x_Embedding[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "o1_Dense_1 (Dense)              (None, 10)           110         lambda[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "oh_Dense_1 (Dense)              (None, 10)           110         o1_Dense_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "oh_Dense_2 (Dense)              (None, 10)           110         oh_Dense_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 20)           0           o1_Dense_1[0][0]                 \n",
      "                                                                 oh_Dense_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concat_Dense (Dense)            (None, 120)          2520        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "ground_truth (Softmax)          (None, 120)          0           concat_Dense[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 13,090\n",
      "Trainable params: 13,090\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# load data and make prediction - RaggedTensor\n",
    "\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import random\n",
    "import bz2\n",
    "\n",
    "def get_dataset(dataset_path, shuffle=False, batch_size=512, drop_remainder=False, repeat=False, processes_per_host=-1):\n",
    "    '''dedicated for YOYI dataset, generate by TextLineDataset'''\n",
    "    \n",
    "    def parse(element):\n",
    "        # process the element (row or batch)\n",
    "        # e.g. \"0\\t16\\t123:1\\t456:1\\t789:1\\n\"\n",
    "        element = tf.strings.regex_replace(element, \":1\", \"\")\n",
    "        element = tf.strings.substr(element, tf.fill(tf.shape(element), 2), tf.strings.length(element)-2)\n",
    "        element = tf.strings.split(element, '\\t')\n",
    "        \n",
    "        # generate features\n",
    "        features_tensor = element[:,1:]\n",
    "        features_tensor = tf.strings.to_hash_bucket_fast(features_tensor, 1024)\n",
    "        \n",
    "        # generate ground_truth\n",
    "        win_price = tf.strings.to_number(element[:,0:1], tf.int64).to_tensor()\n",
    "        # fake the bidding price\n",
    "        random_num = tf.cast(\n",
    "                        tf.random.normal(tf.shape(win_price), \n",
    "                                          mean=0.0, \n",
    "                                          stddev=32.0, \n",
    "                                          dtype=tf.float32),\n",
    "                        tf.int64)\n",
    "        label = tf.cast(\n",
    "                    tf.math.greater(random_num, \n",
    "                                    tf.zeros(tf.shape(random_num), \n",
    "                                             dtype=tf.int64)), \n",
    "                    tf.int64)\n",
    "        ground_truth_tensor = tf.concat([label , win_price + random_num, win_price], axis=-1) \n",
    "        \n",
    "        return ({'features':features_tensor}, {'ground_truth': ground_truth_tensor})\n",
    "    \n",
    "    dataset = tf.data.TextLineDataset(dataset_path)\n",
    "    dataset = dataset.batch(batch_size, drop_remainder=drop_remainder)\n",
    "    dataset = dataset.map(parse, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "## get the ground truth\n",
    "test_dataset_ground_truth = []\n",
    "with open('./test_dataset/test_set') as file:\n",
    "    while True:\n",
    "        data = file.readline()\n",
    "        if not data:\n",
    "            break\n",
    "        win_price = int(data.split('\\t')[1])\n",
    "        test_dataset_ground_truth.append(win_price)\n",
    "        \n",
    "test_dataset = get_dataset('./test_dataset/test_set', shuffle=False, batch_size=config.AI_BATCH_SIZE, drop_remainder=False, repeat=False)\n",
    "pdf = model.predict(test_dataset)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# calculate prediction price, index of prediction price\n",
    "\n",
    "MAX_IDX = int((B_LIMIT - B_START) / B_DELTA - 1)\n",
    "p_idx = []\n",
    "p = []\n",
    "for record in pdf:\n",
    "    record = record.tolist()\n",
    "    # calculate the index of prediction price\n",
    "    idx = record.index(max(record))\n",
    "    p_idx.append(idx)\n",
    "    # calculate prediction price\n",
    "    p.append(B_START + idx * B_DELTA)\n",
    "\n",
    "# load ground truth of bidding price and winning price, calculate their index\n",
    "z = test_dataset_ground_truth\n",
    "z_idx = [min(math.floor((x - B_START) / B_DELTA), MAX_IDX) for x in z]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# evaluation\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate(pdf, p, p_idx, z, z_idx):\n",
    "    r = []  # the result of prediction (win or lose)\n",
    "    anlp = 0\n",
    "    wr_p = []\n",
    "    value = 0\n",
    "    for i in range(len(pdf)):\n",
    "        # number of wins\n",
    "        r.append(1 if p[i]>z[i] else 0)\n",
    "        # anlp\n",
    "#         anlp += math.log(pdf[i][z_idx[i]])\n",
    "        anlp += math.log(max(pdf[i][z_idx[i]], 1e-10))\n",
    "        # c-index\n",
    "        wr_p.append(sum(pdf[i][0:p_idx[i]]))\n",
    "        # value\n",
    "        value += z[i] * r[i]\n",
    "\n",
    "    print('Number of wins =', sum(r), '/', len(r), ', {:.2f}%'.format(sum(r)/len(r)*100))\n",
    "    mae = mean_absolute_error(p, z)\n",
    "    print('MAE = {:.2f}'.format(mae))\n",
    "    print('ANLP =', str(-anlp/len(pdf)))\n",
    "    c_index = roc_auc_score(r, wr_p)\n",
    "    print(\"C-Index = {:.4f}\".format(c_index))\n",
    "    print('Value = {:.2f}'.format(value/sum(r)))\n",
    "    \n",
    "evaluate(pdf, p, p_idx, z, z_idx)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of wins = 12728784 / 38980658 , 32.65%\n",
      "MAE = 83.37\n",
      "ANLP = 3.410943188889108\n",
      "C-Index = 0.9374\n",
      "Value = 38.54\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}